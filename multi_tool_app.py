# multi_tool_app.py
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Application Â«â€¯BoÃ®te Ã  outilsâ€¯Â» â€“ 5 modules dans 1 seul Streamlit
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from __future__ import annotations
import csv, io, re, tempfile, os, sys
from datetime import datetime
from itertools import product
from pathlib import Path
from typing import Dict, Tuple, List

import pandas as pd
import streamlit as st

# â•â•â•â•â•â•â•â•â•â•â• IMPORTS OPTIONNELS â•â•â•â•â•â•â•â•â•â•â•
# libpostal (amÃ©liore le dÃ©coupage dâ€™adresse)
try:
    from postal.parser import parse_address            # type: ignore
    USE_POSTAL = True
except ImportError:
    USE_POSTAL = False

# Outlook (gÃ©nÃ©ration de brouillon)
try:
    import win32com.client as win32                    # type: ignore
    IS_OUTLOOK = True
except ImportError:
    IS_OUTLOOK = False

# psutil (affiche lâ€™usage RAM)
try:
    import psutil                                      # type: ignore
    RAM = lambda: f"{psutil.Process().memory_info().rss/1_048_576:,.0f}â€¯Mo"
except ModuleNotFoundError:
    psutil = None
    RAM = lambda: "n/a"                                # type: ignore

TODAY = datetime.today().strftime("%y%m%d")
st.set_page_config("BoÃ®te Ã  outils", "ğŸ› ", layout="wide")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ FONCTIONS UTILITAIRES GLOBALES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(show_spinner=False, hash_funcs={io.BytesIO: lambda _: None})
def read_csv(buf: io.BytesIO) -> pd.DataFrame:
    """Lecture robuste CSVâ€¯: dÃ©tecte encodage & sÃ©parateur."""
    for enc in ("utf-8", "latin1", "cp1252"):
        buf.seek(0)
        try:
            sample = buf.read(2048).decode(enc, errors="ignore")
            sep = csv.Sniffer().sniff(sample, delimiters=";,|\t").delimiter
            buf.seek(0)
            return pd.read_csv(buf, sep=sep, encoding=enc, engine="python", on_bad_lines="skip")
        except Exception:
            continue
    raise ValueError("CSV illisible (encodage ou sÃ©parateur)")

@st.cache_data(show_spinner=False, hash_funcs={io.BytesIO: lambda _: None})
def read_any(upload) -> pd.DataFrame:
    """Lecture CSV / Excel, avec caching."""
    name = upload.name.lower()
    if name.endswith(".csv"):
        return read_csv(io.BytesIO(upload.getvalue()))
    if name.endswith((".xlsx", ".xls")):
        return pd.read_excel(upload, engine="openpyxl", dtype=str)
    raise ValueError("Extension non gÃ©rÃ©e")

def to_m2(s: pd.Series) -> pd.Series:
    return s.astype(str).str.zfill(6)

def sanitize_code(code: str) -> str | None:
    """VÃ©rifie quâ€™un code M2 compte 6â€¯chiffres (ou 5â€¯â†’â€¯paddÃ© Ã  6)."""
    s = str(code).strip()
    if not s.isdigit():
        return None
    if len(s) == 5:
        s = s.zfill(6)
    return s if len(s) == 6 else None

def sanitize_numeric(series: pd.Series, width: int) -> Tuple[pd.Series, pd.Series]:
    """Normalise champs numÃ©riquesâ€¯; renvoie sÃ©rie nettoyÃ©e + masque invalides."""
    s = series.astype(str).str.strip()
    s_pad = s.apply(lambda x: x.zfill(width) if x.isdigit() and len(x) <= width else x)
    bad = ~s_pad.str.fullmatch(fr"\d{{{width}}}")
    return s_pad, bad

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  PAGEÂ 1 â€“ MISE Ã€ JOUR M2 (PC & Appairage) â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def page_update_m2():
    st.header("ğŸ”„Â Mise Ã  jour des codesÂ M2")
    tab_pc, tab_cli = st.tabs(["ğŸ“‚Â PersonalÂ Catalogue", "ğŸ¤Â Appairage client"])

    # --- Sousâ€‘page PC ---
    with tab_pc:
        LOTS_PC = {
            "old": ("DonnÃ©es Nâ€‘1", "Ref produit", "M2Â ancien"),
            "new": ("DonnÃ©es N"  , "Ref produit", "M2Â nouveau"),
        }
        uploader_state("pc", LOTS_PC)

        if st.button("GÃ©nÃ©rer M2_MisAJour", key="btn_pc"):
            if not all(st.session_state[f"pc_{k}_files"] for k in LOTS_PC):
                st.warning("Chargez Nâ€‘1 et N."); st.stop()
            maj = build_m2_update("pc", LOTS_PC)
            st.download_button(
                "TÃ©lÃ©charger M2_MisAJour.csv",
                maj.to_csv(index=False, sep=";"),
                file_name=f"M2_MisAJour_{TODAY}.csv",
                mime="text/csv",
                key="dl_pc",
            )
            st.dataframe(maj.head())

    # --- Sousâ€‘page Appairage ---
    with tab_cli:
        LOTS_CL = {
            "old": ("DonnÃ©es Nâ€‘1", "Ref produit", "M2Â ancien"),
            "new": ("DonnÃ©es N"  , "Ref produit", "M2Â nouveau"),
            "map": ("Mapping"    , "M2Â ancien",   "Code famille client"),
        }
        uploader_state("cl", LOTS_CL)

        extra_cols = st.multiselect(
            "Colonnes suppl. pour a_remplir.csv",
            options=st.session_state.get("cl_cols", []),
        )

        if st.button("GÃ©nÃ©rer appairage", key="btn_cl"):
            if not all(st.session_state[f"cl_{k}_files"] for k in LOTS_CL):
                st.warning("Chargez les 3 fichiers."); st.stop()
            fam, missing = build_appairage("cl", LOTS_CL, extra_cols)
            st.download_button(
                "TÃ©lÃ©charger appairage_M2_famille.csv",
                fam.to_csv(index=False, sep=";"),
                file_name=f"appairage_M2_CodeFamilleClient_{TODAY}.csv",
                mime="text/csv",
            )
            st.download_button(
                "TÃ©lÃ©charger a_remplir.csv",
                missing.to_csv(index=False, sep=";"),
                file_name=f"a_remplir_{TODAY}.csv",
                mime="text/csv",
            )
            st.dataframe(fam.head())

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Helpers dÃ©diÃ©s Ã  la page 1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def uploader_state(prefix: str, lots: Dict[str, Tuple[str, str, str]]):
    """Petit composant uploader avec mÃ©morisation des fichiers dÃ©jÃ  chargÃ©s."""
    for key in lots:
        st.session_state.setdefault(f"{prefix}_{key}_files", [])
        st.session_state.setdefault(f"{prefix}_{key}_names", [])

    cols = st.columns(len(lots))
    for (key, (title, lab_ref, lab_val)), col in zip(lots.items(), cols):
        with col:
            st.subheader(title)
            ups = st.file_uploader("DÃ©poserâ€¦", type=("csv", "xlsx"),
                                   accept_multiple_files=True,
                                   key=f"{prefix}_{key}_up")
            if ups:
                new_ups = [u for u in ups
                           if u.name not in st.session_state[f"{prefix}_{key}_names"]]
                st.session_state[f"{prefix}_{key}_files"] += new_ups
                st.session_state[f"{prefix}_{key}_names"] += [u.name for u in new_ups]
                st.success(f"{len(new_ups)} fichier(s) ajoutÃ©(s)")
            st.number_input(lab_ref, 1, 50, 1, key=f"{prefix}_{key}_ref")
            st.number_input(lab_val, 1, 50, 2, key=f"{prefix}_{key}_val")
            st.caption(f"{len(st.session_state[f'{prefix}_{key}_files'])}Â fichier(s) â€¢ RAM {RAM()}")

def add_cols(df: pd.DataFrame, ref_i: int, m2_i: int,
             ref_label: str, m2_label: str) -> pd.DataFrame:
    sub = df.iloc[:, [ref_i-1, m2_i-1]].copy()
    sub.columns = [ref_label, m2_label]
    sub[m2_label] = to_m2(sub[m2_label])
    return sub

def build_m2_update(prefix: str, lots: Dict[str, Tuple[str, str, str]]) -> pd.DataFrame:
    dfs = {}
    for k in lots:
        parts = [read_any(f) for f in st.session_state[f"{prefix}_{k}_files"]]
        dfs[k] = pd.concat(parts, ignore_index=True).drop_duplicates()

    old_df = add_cols(dfs["old"],
                      st.session_state[f"{prefix}_old_ref"],
                      st.session_state[f"{prefix}_old_val"],
                      "Ref", "M2_ancien")
    new_df = add_cols(dfs["new"],
                      st.session_state[f"{prefix}_new_ref"],
                      st.session_state[f"{prefix}_new_val"],
                      "Ref", "M2_nouveau")

    merged = new_df.merge(old_df[["Ref", "M2_ancien"]], on="Ref", how="left")
    return merged.groupby("M2_nouveau")["M2_ancien"].agg(
        lambda s: s.value_counts().idxmax() if s.notna().any() else pd.NA
    ).reset_index()

def build_appairage(prefix: str, lots: Dict[str, Tuple[str, str, str]],
                    extra_cols: List[str]) -> Tuple[pd.DataFrame, pd.DataFrame]:
    dfs = {}
    for k in lots:
        parts = [read_any(f) for f in st.session_state[f"{prefix}_{k}_files"]]
        dfs[k] = pd.concat(parts, ignore_index=True).drop_duplicates()

    old_df = add_cols(dfs["old"],
                      st.session_state[f"{prefix}_old_ref"],
                      st.session_state[f"{prefix}_old_val"],
                      "Ref", "M2_ancien")
    new_df = add_cols(dfs["new"],
                      st.session_state[f"{prefix}_new_ref"],
                      st.session_state[f"{prefix}_new_val"],
                      "Ref", "M2_nouveau")

    map_df = dfs["map"].iloc[:, [st.session_state[f"{prefix}_map_ref"]-1,
                                 st.session_state[f"{prefix}_map_val"]-1]].copy()
    map_df.columns = ["M2_ancien", "Code_famille_Client"]
    map_df["M2_ancien"] = to_m2(map_df["M2_ancien"])
    old_df["M2_ancien"] = to_m2(old_df["M2_ancien"])

    merged = (new_df.merge(old_df[["Ref", "M2_ancien"]], on="Ref", how="left")
                     .merge(map_df, on="M2_ancien", how="left"))
    st.session_state["cl_cols"] = list(merged.columns)         # pour multiselect

    fam = merged.groupby("M2_nouveau")["Code_famille_Client"].agg(
        lambda s: s.value_counts().idxmax() if s.notna().any() else pd.NA
    ).reset_index()

    missing = fam[fam["Code_famille_Client"].isna()].copy()
    if extra_cols:
        good = [c for c in extra_cols if c in merged.columns]
        missing = missing.merge(merged[["M2_nouveau"] + good].drop_duplicates(),
                                on="M2_nouveau", how="left")
    return fam, missing

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  PAGEÂ 2 â€“ CLASSIFICATION CODE â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def page_classification():
    st.header("ğŸ§©Â Classification Code")
    pair_file = st.file_uploader("1) Appairage M2 âœ CodeÂ famille (CSV)", type="csv")
    if not pair_file:
        st.info("Commence par charger l'appairage M2."); st.stop()

    pair_df = read_csv(io.BytesIO(pair_file.getvalue()))
    exp_cols = {"M2", "Code_famille_Client"}
    if not exp_cols.issubset(pair_df.columns):
        st.error(f"Le fichier doit contenirÂ : {exp_cols}"); st.stop()
    pair_df["M2"] = to_m2(pair_df["M2"])
    st.success(f"{len(pair_df)}Â lignes chargÃ©es")
    st.dataframe(pair_df.head())

    data_files = st.file_uploader("2) Fichiers Ã  classifier (CSV/XLSX/XLS)",
                                  accept_multiple_files=True,
                                  type=("csv", "xlsx", "xls"))
    if not data_files:
        st.info("Ajoute un ou plusieurs fichiers Ã  classifier."); st.stop()

    results = []
    for upl in data_files:
        df = read_any(upl)
        st.markdown(f"##### {upl.name}")
        cols = [f"{i+1} â€“Â {c}" for i, c in enumerate(df.columns)]
        idx = st.selectbox("Colonne M2", cols, key=f"m2col_{upl.name}")
        m2_col = df.columns[int(idx.split(' â€“')[0]) - 1]
        df["M2"] = to_m2(df[m2_col])
        merged = df.merge(pair_df[["M2", "Code_famille_Client"]], on="M2", how="left")
        st.write(f"â†’ {merged['Code_famille_Client'].notna().sum()} / {len(df)}Â lignes appariÃ©es")
        results.append(merged)
        with st.expander("AperÃ§u"):
            st.dataframe(merged.head())

    final = pd.concat(results, ignore_index=True)
    fname = f"DATA_CLASSIFIEE_{datetime.today().strftime('%y%m%d_%H%M%S')}.csv"
    st.download_button("â¬‡ï¸Â TÃ©lÃ©charger les donnÃ©es classifiÃ©es", final.to_csv(index=False, sep=";"),
                       file_name=fname, mime="text/csv")
    st.success("Classification terminÃ©eÂ !")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  PAGEÂ 3 â€“ PF1Â â†’Â PF6 GENERATOR â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def page_multiconnexion():
    st.header("ğŸ“¦Â GÃ©nÃ©rateur PF1â€¯â†’â€¯PF6 (Multiconnexion)")
    integration_type = st.radio("Type dâ€™intÃ©gration", ["cXML", "OCI"], horizontal=True)

    st.markdown(
        "TÃ©lÃ©chargez le template, remplissezâ€‘le puis uploadez votre fichier.  \n"
        "Colonnes requisesÂ : **NumÃ©ro de compte** (7â€¯chiffres), **Raison sociale**, "
        "**Adresse**, **ManagingBranch** (4â€¯chiffres)."
    )

    # Template
    with st.expander("ğŸ“‘ Template dfrecu.xlsx"):
        tpl_cols = ["NumÃ©ro de compte", "Raison sociale", "Adresse", "ManagingBranch"]
        tpl_buf = io.BytesIO()
        pd.DataFrame([{c: "" for c in tpl_cols}]).to_excel(tpl_buf, index=False)
        tpl_buf.seek(0)
        st.download_button("ğŸ“¥ TÃ©lÃ©charger le template", tpl_buf.getvalue(),
                           file_name="dfrecu_template.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

    up_file = st.file_uploader("ğŸ“„ Fichier dfrecu", type=("csv", "xlsx", "xls"))
    if not up_file:
        st.info("Charge un fichier dfrecu pour continuer."); st.stop()

    col1, col2, col3 = st.columns(3)
    with col1:  entreprise     = st.text_input("ğŸ¢ Entreprise").strip()
    with col2:  punchout_user  = st.text_input("ğŸ‘¤ punchoutUserID")
    with col3:  domain         = st.selectbox("ğŸŒ Domain", ["NetworkID", "DUNS"])
    identity      = st.text_input("ğŸ†” Identity")
    vm_choice     = st.radio("ViewMasterCatalog", ["True", "False"], horizontal=True)
    pc_enabled    = st.radio("Personal CatalogueÂ ?", ["True", "False"], horizontal=True)
    pc_name       = st.text_input("Nom du catalogue (sans PC_)", placeholder="CATALOGUE").strip() if pc_enabled == "True" else ""

    if st.button("ğŸš€ GÃ©nÃ©rer PF", key="btn_pf"):
        required = [entreprise, punchout_user, identity,
                    (pc_enabled == "False" or pc_name)]
        if not all(required):
            st.warning("Remplis tous les champs requis."); st.stop()

        df_src = read_any(up_file)
        if {"NumÃ©ro de compte", "ManagingBranch"} - set(df_src.columns):
            st.error("Colonnes manquantes dans le fichier."); st.stop()

        acc_series, bad_acc = sanitize_numeric(df_src["NumÃ©ro de compte"], 7)
        man_series, bad_man = sanitize_numeric(df_src["ManagingBranch"], 4)
        if bad_acc.any() or bad_man.any():
            st.error("NumÃ©ro de compte ou ManagingBranch invalide(s)."); st.stop()

        df_src["NumÃ©ro de compte"] = acc_series
        df_src["ManagingBranch"]   = man_series

        # build_tables vient du code original (non reproduit ici pour concision)
        tables: List[pd.DataFrame] = build_tables(df_src)  # type: ignore

        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        labels = ["PF1", "PF2", "PF3", "PF4", "PF5"] + (["PF6"] if integration_type == "cXML" else [])
        files_bytes = {}
        for label, df in zip(labels, tables):
            data_bytes = to_xlsx(df)
            fname = f"{label}_{entreprise}_{ts}.xlsx"
            files_bytes[fname] = data_bytes
            st.download_button(f"â¬‡ï¸ {label}", data=data_bytes, file_name=fname,
                               mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
        st.success("âœ… Fichiers prÃªtsâ€¯!")
        st.dataframe(tables[0].head())

        # Option Outlook
        st.markdown("---")
        st.subheader("ğŸ“§ Exporter via Outlook Desktop")
        if IS_OUTLOOK:
            dest = st.text_input("Destinataire (optionnel)")
            subj = f"Fichiers PF â€“ {entreprise} ({ts})"
            if st.button("Ouvrir un brouillon Outlook"):
                create_outlook_draft(list(files_bytes.items()), to_=dest, subject=subj)
                st.success("Brouillon Outlook ouvert.")
        else:
            st.info("Automatisation Outlook indisponible sur cet environnement.")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  PAGEÂ 4 â€“ DFRX/AFRX (PC & MÃ J M2) â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def page_dfrx_pc():
    st.header("ğŸ› ï¸Â GÃ©nÃ©rateur PC + Mise Ã  jour M2")
    nav2 = st.radio("Choisir lâ€™outil", ["GÃ©nÃ©rateur PC", "Mise Ã  jour M2"], horizontal=True)
    if nav2 == "GÃ©nÃ©rateur PC":
        generator_pc()
    else:
        generator_maj_m2()

# â–º Sousâ€‘composants simplifiÃ©s (extraits du code initial)
def generator_pc():
    st.subheader("GÃ©nÃ©rateur PC")
    codes_file = st.file_uploader("Codes produit", type=("csv", "xlsx", "xls"))
    if not codes_file: st.stop()
    col_idx_codes = st.number_input("Colonne CodesÂ M2 (1=A)", 1, 50, 1)
    compte_file = st.file_uploader("NumÃ©ros de compte", type=("csv", "xlsx", "xls"))
    if not compte_file: st.stop()
    col_idx_comptes = st.number_input("Colonne comptes (1=A)", 1, 50, 1)
    entreprise = st.text_input("Entreprise")
    statut     = st.selectbox("Statut", ["", "INCLUDE", "EXCLUDE"])
    if st.button("ğŸš€ GÃ©nÃ©rer PC"):
        df_codes   = read_any(codes_file)
        df_comptes = read_any(compte_file)
        codes_raw = df_codes.iloc[:, col_idx_codes-1].dropna()
        comptes   = df_comptes.iloc[:, col_idx_comptes-1].dropna().astype(str).str.strip()
        codes = codes_raw.astype(str).apply(sanitize_code)
        if codes.isna().any():
            st.error("Codes M2 invalides."); st.stop()
        dstr = TODAY
        df1 = pd.DataFrame({
            0: [f"PC_PROFILE_{entreprise}"] * len(codes),
            1: [statut] * len(codes),
            2: [None] * len(codes),
            3: [f"M2_{c}" for c in codes],
            4: ["frxProductCatallog:Online"] * len(codes),
        }).drop_duplicates()
        st.download_button("DFRXHYBRPCP", df1.to_csv(index=False, header=False, sep=";"),
                           file_name=f"DFRXHYBRPCP{dstr}0000", mime="text/plain")
        st.success("Fichiers gÃ©nÃ©rÃ©s.")

def generator_maj_m2():
    st.subheader("Mise Ã  jour M2 avant gÃ©nÃ©ration")
    codes_file = st.file_uploader("Codes produit", type=("csv", "xlsx", "xls"), key="maj_codes")
    if not codes_file: st.stop()
    col_idx_codes = st.number_input("Colonne CodesÂ M2 (1=A)", 1, 50, 1)
    compte_file = st.file_uploader("NumÃ©ros de compte", type=("csv", "xlsx", "xls"), key="maj_comptes")
    if not compte_file: st.stop()
    col_idx_comptes = st.number_input("Colonne comptes (1=A)", 1, 50, 1)
    map_file = st.file_uploader("Fichier M2_MisAJour", type=("csv", "xlsx", "xls"))
    if not map_file: st.stop()
    col_idx_old = st.number_input("Colonne M2 ancien", 1, 50, 1)
    col_idx_new = st.number_input("Colonne M2 nouveau", 1, 50, 2)
    entreprise = st.text_input("Entreprise")
    statut     = st.selectbox("Statut", ["", "INCLUDE", "EXCLUDE"])

    if st.button("ğŸš€ GÃ©nÃ©rer MÃ J"):
        df_codes   = read_any(codes_file)
        df_comptes = read_any(compte_file)
        df_map     = read_any(map_file)
        raw_codes  = df_codes.iloc[:, col_idx_codes-1]
        comptes    = df_comptes.iloc[:, col_idx_comptes-1].dropna().astype(str).str.strip()
        codes      = raw_codes.astype(str).apply(sanitize_code)
        old_codes  = df_map.iloc[:, col_idx_old-1].astype(str).apply(sanitize_code)
        new_codes  = df_map.iloc[:, col_idx_new-1].astype(str).apply(sanitize_code)
        mapping = pd.Series(new_codes.values, index=old_codes).dropna().to_dict()
        updated = codes.map(lambda c: mapping.get(c, c))
        dstr = TODAY
        df1 = pd.DataFrame({
            0: [f"PC_PROFILE_{entreprise}"] * len(updated),
            1: [statut] * len(updated),
            2: [None] * len(updated),
            3: [f"M2_{c}" for c in updated],
            4: ["frxProductCatallog:Online"] * len(updated),
        }).drop_duplicates()
        st.download_button("DFRXHYBRPCP", df1.to_csv(index=False, header=False, sep=";"),
                           file_name=f"DFRXHYBRPCP{dstr}0000", mime="text/plain")
        st.success("Fichiers gÃ©nÃ©rÃ©s.")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  PAGEÂ 5 â€“ CPN GENERATOR â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def page_cpn():
    st.header("ğŸ“‘Â GÃ©nÃ©rateur CPN (DFRXHYBCPNA / AFRXHYBCPNA)")
    colA, colB = st.columns(2)
    with colA:
        main_file = st.file_uploader("Appairage client", type=("csv", "xlsx", "xls"))
    with colB:
        cli_file  = st.file_uploader("PÃ©rimÃ¨tre (comptes client)", type=("csv", "xlsx", "xls"))
    if not (main_file and cli_file):
        st.stop()

    df_main = read_any(main_file)
    max_cols = len(df_main.columns)
    col_int = st.selectbox("Colonne RÃ©f. interne", range(1, max_cols+1), 0)
    col_cli = st.selectbox("Colonne RÃ©f. client", range(1, max_cols+1), 1 if max_cols > 1 else 0)

    if st.button("ğŸš€ GÃ©nÃ©rer CPN"):
        df_cli = read_any(cli_file)
        series_int = df_main.iloc[:, col_int-1].astype(str).str.strip()
        invalid = ~series_int.str.fullmatch(r"\d{8}")
        if invalid.any():
            st.error("RÃ©f. interne invalide (doit contenir 8 chiffres).")
            st.dataframe(series_int[invalid]); st.stop()
        series_cli = df_cli.iloc[:, 0].astype(str).str.strip()
        pf = pd.DataFrame(product(series_int, series_cli),
                          columns=["1", "2"])
        pf["3"] = pf["1"]
        today = TODAY
        dfrx_name = f"DFRXHYBCPNA{today}0000"
        afrx_name = f"AFRXHYBCPNA{today}0000"
        afrx_txt = (f"DFRXHYBCPNA{today}000148250201IT"
                    f"DFRXHYBCPNA{today}CPNAHYBFRX                    OK000000")
        st.download_button("â¬‡ï¸ DFRX (TSV)", pf.to_csv(sep="\t", index=False, header=False).encode(),
                           file_name=dfrx_name, mime="text/tab-separated-values")
        st.download_button("â¬‡ï¸ AFRX (TXT)", afrx_txt, file_name=afrx_name, mime="text/plain")
        st.success("Fichiers gÃ©nÃ©rÃ©s.")
        st.dataframe(pf.head())

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  MENU PRINCIPAL â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
PAGES = {
    "Mise Ã  jourÂ M2": page_update_m2,
    "ClassificationÂ Code": page_classification,
    "PF1Â â†’Â PF6 Generator": page_multiconnexion,
    "GÃ©nÃ©rateur PC / MÃ Jâ€¯M2": page_dfrx_pc,
    "CPN Generator": page_cpn,
}
choice = st.sidebar.radio("Navigation", list(PAGES.keys()))
PAGES[choice]()
